# LLM Detection Tool

## Overview
This project provides a unified tool for detecting text generated by different large language models. It includes multiple text generators and detectors, as well as a web application for remote use.

## Project Structure

The project has the following directory structure:
- `generators/`: contains modules that implement different text generators.
- `detectors/`: contains modules that implement different text detectors.
- `models/`: contains the pre-trained models used by the generators and detectors.
- `tests/`: contains unit tests for the different algorithems.
- `preprocessing/`: contains scripts for preprocessing text data.
- `utils/`: contains utility modules used by the generators and detectors.
- `examples/`: contains example usage.
- `app.py`: the main gradio application for running the web interface.
- `requirements.txt`: a file specifying the Python dependencies required by the project.



```bash
.
├── generators
│   └── LLMGenerator.py
│
├── detectors
│   ├── GPTDetector.py
│   └── WatermarkDetector.py
│
├── models
│
├── preprocessing
│   ├── __init__.py
│   └── custom_datasets.py
│
├── tests
│   ├── __init__.py
│   ├── test_detectgpt.py
│   └── test_watermark.py
│
├── examples
│   └── watermark_example.py
│
├── app.py
├── setup.py
├── requirements.txt
├── README.md
│
└── utils
    ├── __init__.py
    ├── base_class.py
    ├── baseline_utils.py
    ├── detectgpt_utils.py
    ├── homoglyphs.py
    ├── mask_fill_utils.py
    ├── normalizers.py
    └── web_format_utils.py
```


## Usage

#### Web Application
To use the project, you can follow these steps:

1. Clone the repository: `git clone https://github.com/yataobian/aigc-detection.git`.
2. Install the required Python packages: `pip install -r requirements.txt`.
3. Run the Setup File: `python setup.py install`.
4. Run the gradio application: `python app.py`.
5. Open the web link and enter some text and click the "Detect" button to see if it is written by human or machine.


#### Local Testing
You can also use the generators and detectors from Python code. Here's an example (you can also see in `./examples` ):

```python
from generators.LLMGenerator import LMGenerator
from detectors.WatermarkDetector import WatermarkDetector

# Instantiate a generator
generator = LMGenerator('gpt2')

# Generate some machine text
prompt = ("The diamondback terrapin or simply terrapin (Malaclemys terrapin) is a species of turtle native to the brackish coastal tidal marshes of the Northeastern and southern United States, and in Bermuda.[6] It belongs to the monotypic genus Malaclemys. It has ")
output_wo_watermark = generator.generate(prompt)
output_w_watermark = generator.generate_with_watermark(prompt)

# Instantiate a detector
detector = WatermarkDetector(vocab=list(generator.tokenizer.get_vocab().values()), gamma=0.5, z_threshold=4.0, \
    device=generator.device, tokenizer=generator.tokenizer,)

# Check if the text is written by machine
print (detector.detect(output_wo_watermark))
print (detector.detect(output_w_watermark))
```
